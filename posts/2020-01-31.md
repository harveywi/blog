# On Functional Software Testing: How Do I Know `f` Is Right For Me?

## Introduction
Programmers write software.  As we write the sofware, we make [mistakes](https://en.wikipedia.org/wiki/Software_bug).  [Lots](https://github.com/scala/bug/issues) of mistakes.
Mistakes that [kill people](https://www.cnn.com/2019/06/26/politics/boeing-737-max-flaw/index.html).  Mistakes that have caused damages on the order of
[trillions of dollars](https://www.ibeta.com/historys-most-expensive-software-bugs/).

Even [coq has bugs](https://github.com/coq/coq/issues).

I'll say it.  Software is crapola.  In virtually any software system, there is a broken crappy part.  We don't yet know how to produce software that is not broken and crappy without
going through contortions of comical proportions.  For example, SQLite has [662 lines
of test code for every line of SQLite code](https://www.sqlite.org/testing.html).  Egads!

Is the situation hopeless?  Well, maybe!  It is certainly a complex phenomenon that
emerges from a combination of factors, including human psychology, industry software
development practices, [pointy-haired bosses](https://en.wikipedia.org/wiki/Pointy-haired_Boss),
trying to build sturdy software when the foundation is a bug-riddled morass.

But maybe the situation is not too hopeless.

In the following weeks we will explore this question from a mathematical perspective.
We will use mathematics to define a defect, and use mathematics to better understand
how defects emerge.  If we are lucky, this exploration will lead us to a principled
methodology for quantifying the value of various software testing methods (how well
they *actually* work) as well as how to get the most value out of testing our own
software.

## Background
### Type Theory: Counting Type Inhabitants
In 2019, [Alex Konovalov](https://alexknvl.com/index.html) published an [excellent collection of notes](https://alexknvl.com/posts/software-testing.html) on software testing methods.
Perhaps by coincidence (or, perhaps not), earlier that year he published an article
called "[Counting Type Inhabitants](https://alexknvl.com/posts/counting-type-inhabitants.html)"
that provides an answer to the question, "How many possible values are there of
a given type?"  Alex and Emily Pillmore gave a [6-hour lecture](https://twitter.com/lambda_conf/status/1115826397656829952) expounding on this
idea at LambdaConf 2019 (highly recommended!).

At this time, it is important to know that the type system of the programming lanaguage
that you are allowed to use at work (e.g., Java or C#, or G-d forbid JavaScript!)
may be a wimpy one: There are a [variety](https://en.wikipedia.org/wiki/Lambda_cube) of type systems out there.  Type theory is very powerful (see the
[Curry-Howard correspondence](https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence)) and has a lot of potential for improving the status quo regarding guaranteeing software
correctness.  However, as of today, the ergonomics are still pretty awkward: It remains
challenging to embrace the pedantry required to encode proofs into type signatures,
and hand-holding computer-assisted proof systems often requires a secondary ["tactics"
language](https://coq.inria.fr/refman/proof-engine/ltac.html).

### Formal Concept Analysis: How To Define Things
At LambdaConf 2017, Paul Phillips gave an incredible keynote titled "The Axes
of Abstraction" ([slides](https://www.slideshare.net/extempore/keynote-lambdaconf-2017-the-axes-of-generalization), [video](https://youtu.be/fOI7TJaojTs)) that explores the question of how to define things without resorting to ad hoc schemes
(cf. [software design patterns](https://en.wikipedia.org/wiki/Software_design_pattern)
and ["clean" code](https://www.oreilly.com/library/view/clean-code/9780136083238/)).
Paul reveals that mathematicians have explored this territory thoroughly, and
provides some background and intuition about extensional/intensional definitions.  He then
introduces us to [formal concept analysis](https://en.wikipedia.org/wiki/Formal_concept_analysis),
which (despite being somewhat of a cottage industry) explores the interactions
of extensional and intensional definitions of a universe ("formal context") of
thingies ("formal concepts"), and how these definitions give rise to a [concept lattice](https://en.wikipedia.org/wiki/Formal_concept_analysis#Concept_lattice_of_a_formal_context).
The concept lattice arises from a binary relation between objects and attributes.
The objects are the atomic items
in our universe, and the attributes are all of the possible yes/no questions that
we can ask about objects in our universe.  Given our universe of attributes (yes/no
questions), it may not be possible to discriminate between two different objects.

I like to think of the concept lattice to be an embodiment of the [Sapir-Whorf
Hypothesis](https://en.wikipedia.org/wiki/Linguistic_relativity): Through concept
lattices, we can see and precisely understand the interplay of our language for
describing the world, and how well it works for this purpose.

### Hoare Logic
Dixit Wikipedia: [Hoare Logic](https://en.wikipedia.org/wiki/Hoare_logic) (named after logician Tony Hoare) is a formal method for reasoning rigorously about the correctness of
computer programs.  It has been around since 1969.  (Yet another amazing technical
development that has been largely ignored in favor of industry snake oils du jour).

Hoare logic is simple to use: Its key tool is the [Hoare triple](https://en.wikipedia.org/wiki/Hoare_logic#Hoare_triple).  Given a chunk of code `C`, a Hoare triple is a
`{P}C{Q}` sandwich of code where `P` is a bunch of assertions (called a *precondition*)
and `Q` is also a bunch of assertions (called a *postcondition*).  [Here](https://www.cs.cmu.edu/~aldrich/courses/654-sp07/slides/7-hoare.pdf) are some
pretty good slides on Hoare logic.


## Hypothesis and Our Journey

I have a hunch that there is a way to combine the ideas above to:

1. Formally reason about software testing and *define* software quality in mathematical
terms.

2. Devise a *practical* strategy for combining various methods to *provably* increase
the quality of the software that we write on a daily basis.

3. Get the most out of the effort that we expend on assuring software quality.
Nobody has the time, stamina, or goodwill to write [662 lines
of test code](https://www.sqlite.org/testing.html) for every line of CRUD or fart app.
We can do better by not blindly flailing around.

There are programming languages and environments that are specialized for high-assurance
software developent (e.g., [SPARK](https://en.wikipedia.org/wiki/SPARK_(programming_language))).
However I am more interested in seeing what we can do with the [Cuisinart](
https://www.scala-lang.org/
) and [Fisher](https://www.ruby-lang.org/en/)-[Price](https://www.python.org/) programming
languages that we use on the job.

So, no cheating: We will [embrace the suck](https://www.careershifters.org/expert-advice/why-embracing-the-suck-is-the-key-to-setting-yourself-free) and use the tools available
to us right here, right now, right smack dab in the middle of wherever we are.
